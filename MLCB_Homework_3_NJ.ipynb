{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natnj/NJ-projects-pub/blob/main/MLCB_Homework_3_NJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLCB Homework 3\n",
        "\n",
        "**Due: Monday Nov 6th at 11:59 PM EDT**\n",
        "\n",
        "This homework has two parts. In the first part, you will work with gene expression data and identify eQTLs.\n",
        "\n",
        "The second part will focus on protein modeling, the goal being to expose you to different tools and data that can help you in your final project. In particular you will be using:\n",
        "\n",
        "- The RCSB PDB database (protein structures)\n",
        "- The ESM protein language model from Meta\n",
        "- AlphaFold2\n",
        "- ESMFold\n",
        "- ProteinMPNN (optional for undergads)\n",
        "\n",
        "If you have any questions, please ask on piazza or at office hours!\n",
        "\n",
        "Copy this notebook, and answer all questions directly in this notebook and complete the missing code where marked with **COMPLETE HERE**.\n",
        "\n",
        "When you are done, submit the .ipynb file as well as PDF to Canvas."
      ],
      "metadata": {
        "id": "L1qRVVbAk8_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Setup (run this)"
      ],
      "metadata": {
        "id": "fiaT0KjHlfgV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDQgDia7rwUQ"
      },
      "outputs": [],
      "source": [
        "!pip install fair-esm\n",
        "!pip install scikit-learn\n",
        "!pip install biopython\n",
        "!pip install matplotlib\n",
        "!pip install torch\n",
        "!pip install pandas\n",
        "!pip install tqdm\n",
        "!wget -O train_esm6_data.pt https://www.dropbox.com/scl/fi/cf103vkoew0s5zys7920d/train_esm6_data.pt?rlkey=v7o2upz9txm0m284g6mgfq0ww&dl=0\n",
        "!wget -O test_esm6_data.pt https://www.dropbox.com/scl/fi/v18bvl57eog1ysjb07nww/test_esm6_data.pt?rlkey=idc0y0nzwfizxxf75kyxbfxdh&dl=0\n",
        "!wget -O train_esm150_data.pt https://www.dropbox.com/scl/fi/i4vazz4twcw38wzaykdq0/train_esm150_data.pt?rlkey=ev7tepsceqc4k5vbwsw5bsw67&dl=0\n",
        "!wget -O test_esm150_data.pt https://www.dropbox.com/scl/fi/yyjk31urec4gdwk8ajppt/test_esm150_data.pt?rlkey=v8o5mzp608w8tmxywqmn4r3ob&dl=0\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import esm\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from Bio.PDB import PDBParser, PDBList\n",
        "from google.colab import files\n",
        "import os\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "esm6_model, esm6_alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "esm6_model.eval()\n",
        "\n",
        "esm150_model, esm150_alphabet = esm.pretrained.esm2_t30_150M_UR50D()\n",
        "esm150_model.eval()\n",
        "\n",
        "AA_NAME_MAP = {\n",
        "  'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
        "  'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N',\n",
        "  'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', 'TER':'*',\n",
        "  'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M','XAA':'X'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Finding eQTLs\n",
        "\n",
        "In this problem, we will examine the sources of variation in gene expression that partition a population into subpopulations."
      ],
      "metadata": {
        "id": "DsC2F9sqG3ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will access and upload them to colab using the following code block."
      ],
      "metadata": {
        "id": "kIsbiezFG8GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://www.dropbox.com/sh/9aozrd1fv0bg1xd/AACCM0Y4J9fFTSv9YSjrKO1ya?dl=0 -O eqtl_data.zip\n",
        "!unzip -o eqtl_data.zip -d eqtl_data\n",
        "os.unlink(\"eqtl_data.zip\")\n",
        "eqtl_data = {}\n",
        "for fname in os.listdir(\"eqtl_data\"):\n",
        "    with open(os.path.join(\"eqtl_data\", fname), \"r\") as R:\n",
        "        eqtl_data[fname] = R.read().encode('utf-8')"
      ],
      "metadata": {
        "id": "jJKTDR1VG7aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are free to use the following function to help you process the raw `ExpData.txt` and `SnpData.txt` files."
      ],
      "metadata": {
        "id": "N1mG4ewXG-2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Processes *Data.txt files\n",
        "\"\"\"\n",
        "Example inp:\n",
        "    Patient Trait1 Trait2 Trait3\n",
        "    A 0.1 0.2 0.3\n",
        "    B 0.4 0.5 0.6\n",
        "    C 0.7 0.8 0.9\n",
        "\n",
        "process_file(inp, \"patient\")\n",
        "    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]]\n",
        "\n",
        "process_file(inp, \"trait\")\n",
        "    {\"Trait1\": [0.1, 0.4, 0.7], \"Trait2\": [0.2, 0.5, 0.8], \"Trait3\": [0.3, 0.6, 0.9]}\n",
        "\"\"\"\n",
        "def process_file(inp, mode):\n",
        "    rows = inp.decode(\"utf-8\").split(\"\\n\")\n",
        "    if mode == \"patient\":\n",
        "        return [[float(val) for val in row.split()[1:]] for row in rows[1:] if row]\n",
        "    elif mode == \"trait\":\n",
        "        res = pd.DataFrame([row.split()[1:] for row in rows if row])\n",
        "        res.columns = res.iloc[0]\n",
        "        return {k: [float(val) for val in v.values()] for k, v in res[1:].to_dict().items()}\n",
        "\n",
        "#process_file(eqtl_data[\"SnpData.txt\"], \"patient\")\n",
        "#process_file(eqtl_data[\"SnpData.txt\"], \"trait\")\n",
        "#process_file(eqtl_data[\"ExpData.txt\"], \"patient\")\n",
        "#process_file(eqtl_data[\"ExpData.txt\"], \"trait\")"
      ],
      "metadata": {
        "id": "Nk8qT_jXHAFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following code block if you would like to process the raw `ExpData.txt` and `SnpData.txt` files in your own way."
      ],
      "metadata": {
        "id": "IkaeKjR0HB4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### COMPLETE HERE ###"
      ],
      "metadata": {
        "id": "rG-77lb-HDcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A) The `ExpData.txt` file contains log-normalized RNA-seq expression data from our population of 1,000 samples, with 5,000 genes profiled for each sample. Do a principal components analysis on this dataset to find the clusters of samples that have similar patterns of gene expression. Plot the output of your analysis.\n",
        "In your plots, be sure the axes are labeled with the components you are displaying in each plot. Also make sure that at least one of your plots colours the points corresponding to the samples with the sub-population that you think they should belong to. (Hint: You can re-use your $k$-means code from PSET 1 to find these sub-populations!)\n",
        "\n",
        "Describe the patterns that you observe. What is the structure inherent in this population?\n",
        "\n",
        "You may find the `matplotlib.pyplot` and `sklearn.decomposition.PCA` packages (already imported) to be useful."
      ],
      "metadata": {
        "id": "LWWx8OX8HFeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### COMPELTE HERE ###"
      ],
      "metadata": {
        "id": "6esRPs2-HHrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**"
      ],
      "metadata": {
        "id": "v1B_96Z-hD7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B) The `SnpData.txt` file contains genotyping data for the same 1,000 samples across 500 SNPs. Each SNP's genotype has been called with reference to the same reference genotype; \"0\" thus represents the reference allele, \"2\" represents the non-reference allele, and \"1\" represents a different allele on each strand.\n",
        "\n",
        "You will find that some of the SNPs (more than 5, less than 100) are eQTLs, that is, they have an effect on the expression of one or more of the genes we collected expression data for. Using whatever model you see fit, search for these eQTLs using the genotyping data and the expression data. **You may not have the computational resources to test all combinations of SNPs and genes, so you should think about smart ways to choose subsets of each to find some eQTLs - you don't have to find all of them!**\n",
        "\n",
        "For three of the eQTLs you found, present the evidence you have for why you think it is an eQTL, and not just associated with the expression of a gene by chance alone. *Be sure to include plots in your analysis to support your hypothesis, and to thoroughly explain the method you used to find eQTLs.* You can assume that the association between genotype and expression is linear for eQTLs. *Don't forget that you should be correcting for the fact that you are performing multiple significance tests.*"
      ],
      "metadata": {
        "id": "9gxPrIzGg2-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### COMPLETE HERE ###"
      ],
      "metadata": {
        "id": "MC5Ioc3og70s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "eQTL 1:\n",
        "\n",
        "eQTL 2:\n",
        "\n",
        "eQTL 3:"
      ],
      "metadata": {
        "id": "7f2ppfnxHKIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C) In the above analysis, we were forced to consider all pairs of SNPs and genes to identify eQTLs. What sources of data that have not been provided as part of this problem would have been useful in constraining the amount of such pairs you had to test? For at least two sources:\n",
        "\n",
        "i. Give a description of what the dataset would look like (i.e. what are the rows and columns of the data matrix? what kinds of values are stored in the matrix?).\n",
        "\n",
        "ii. Explain how you would use it to filter out pairs of SNPs and genes that are unlikely to be associated with one another."
      ],
      "metadata": {
        "id": "v-IH-ed2HMQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**:\n",
        "\n",
        "Source 1:\n",
        "\n",
        "i.\n",
        "\n",
        "ii.\n",
        "\n",
        "Source 2:\n",
        "\n",
        "i.\n",
        "\n",
        "ii."
      ],
      "metadata": {
        "id": "aamWaOWnHVQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Protein Language Models\n",
        "\n",
        "In this problem we will explore protein language models. The goal is to give you some intuitions as to what these models learn during the pretraining process and how they can be used in downstream applications.\n",
        "\n",
        "Protein language models are trained using the masked language modeling objective: given an input sequence, a subset of amino acids are masked and the model is tasked with predicting the masked tokens.\n",
        "\n",
        "As we will see below, this allows the network to learns complex features of proteins.\n",
        "\n",
        "### 2.A Amino Acid Embeddings\n",
        "\n",
        "In this first part, we will explore how PLM's learn embeddings (i.e vectors of features) that represent amino acids.\n",
        "\n",
        "#### 2.A.1 Question\n",
        "\n",
        "Here we provide you with a vector for each amino acid. Run a dimensionality reduction startegy (ex: t-SNE) to visualize the amino acids in 2D. You can use whatever method you see fit but if you need help getting started, check out this link: https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
        "\n",
        "Note: when using the TSNE implementation above, you may want to use a small value for the perplexity, 3 seemed to work well.\n",
        "\n"
      ],
      "metadata": {
        "id": "vxRuKSYor1uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary mapping an amino acid to its vector\n",
        "def get_aa_embeddings(model, alphabet):\n",
        "  embedding_matrix = model.embed_tokens.weight.data.numpy()\n",
        "  aa_tokens = alphabet.standard_toks[:-2]\n",
        "  aa_to_index = alphabet.to_dict()\n",
        "  aa_to_embeddings = {aa: embedding_matrix[aa_to_index[aa]] for aa in aa_tokens}\n",
        "  return aa_to_embeddings\n",
        "\n",
        "\n",
        "# COMPLETE HERE\n",
        "# Reduce to 2D using t-SNE or other technique and inspect visually\n",
        "# You can do it for both models and compare!\n",
        "esm6_aa_embeddings = get_aa_embeddings(esm6_model, esm6_alphabet)\n",
        "esm150_aa_embeddings = get_aa_embeddings(esm150_model, esm150_alphabet)\n"
      ],
      "metadata": {
        "id": "mX-TqIwPO3tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.A.2 Question\n",
        "\n",
        "Comment on your observations. In particular, pick 2 clusters and identify what is similar about the amino acids in these clusters (think of their chemical properties). You may refer to Wikipedia and other sources for information regarding the chemical properties of amino acids. No need to run a clustering algorithm, just visually inspect. How do the projections compare between the two models?"
      ],
      "metadata": {
        "id": "2qd9ArPHO2-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer here**:"
      ],
      "metadata": {
        "id": "wKeItFaqO9EV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.B Sequence embeddings\n",
        "\n",
        "In this second part, we will use sequence level embeddings and build a simple classifier to predict protein sub-cellular location, specifically if a protein is a membrane-protein or not.\n",
        "\n",
        "#### 2.B.1 Question\n",
        "\n",
        "Embeddings were precomputed for you. All you need to do is train a classifier. Here you are welcome to go as complex as you want to, but the simplest approach would be to train a logistic regression model using sklearn:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "When using LogisticRegression, set C=10 and max_iter=1000 for best results.\n",
        "\n",
        "Make sure to train on the training set, and evaluate your performance on the test set."
      ],
      "metadata": {
        "id": "WFmy-RedNp7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_esm6 = torch.load(\"/content/train_esm6_data.pt\")\n",
        "test_esm6 = torch.load(\"/content/test_esm6_data.pt\")\n",
        "\n",
        "train_esm150 = torch.load(\"/content/train_esm150_data.pt\")\n",
        "test_esm150 = torch.load(\"/content/test_esm150_data.pt\")\n",
        "\n",
        "# COMPLETE HERE\n",
        "# Train a classifier using whatever tool you prefer (simplest is sklearn's logisitc regression above!)\n",
        "# When using LogisticRegression, set C=10 and max_iter=1000 for best results\n",
        "# The data is provided as a list of tuples (vector, label)"
      ],
      "metadata": {
        "id": "Ic1GRxFep5Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.B.2 Question\n",
        "\n",
        "Compute both accuracy and ROC-AUC (see sklearn's roc_auc_score). Which model performed best on the test set?"
      ],
      "metadata": {
        "id": "9O1Yo5-KwQq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**:"
      ],
      "metadata": {
        "id": "2lreWm9-wqE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Protein Structure Prediction\n",
        "\n",
        "In this problem, you will get some experience working with structure prediction models.\n",
        "\n",
        "### 3.A Contact Prediction\n",
        "\n",
        "One way to get a rough idea of a protein's 3D structure is to look at its contact map. Pick your favorite protein from the PDB (https://www.rcsb.org/). If the protein has multiple chain, specificy which chain should be loaded. Make sure it isn't too long, it should be less than 400 amino acids. Also try to avoid proteins with missing residues (faded letters in the sequence when using the 3D view on the rcsb website). If you get an error loading the PDB, try a different one. If you struggle to find one that works, you may use for example \"1A0K\".\n",
        "\n",
        "#### 3.A.1 Question\n",
        "\n",
        "Which protein did you choose and why?"
      ],
      "metadata": {
        "id": "ZUKjAzsltGU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**:"
      ],
      "metadata": {
        "id": "9fTMO5APuhVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.A.2 Question\n",
        "\n",
        "Using the code below, load the protein sequence and its structure.\n",
        "\n",
        "Then complete the code to compute the pairwise contacts between the residues."
      ],
      "metadata": {
        "id": "knZz50peujbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE HERE\n",
        "# If you get an error, try a different PDB entry\n",
        "PDB_ID = \"\" # The PDB ID of the protein you chose\n",
        "PDB_CHAIN = \"\" # The chain to load (you can view chains in the 3D view on rcsb.org)\n",
        "\n",
        "\n",
        "def compute_contacts(coords, threshold=9.0):\n",
        "  \"\"\"Compute the pairwise contacts.\n",
        "\n",
        "  Here we define a contact as the C-alpha atom\n",
        "  of 2 amino acids being within 9 Angstrom of each other.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  coords:\n",
        "    array of shape (num_residues, 3)\n",
        "  threshold:\n",
        "    distance threshold to consider a contact\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  contacts:\n",
        "    binary array of shape (num_residues, num_residues)\n",
        "\n",
        "  \"\"\"\n",
        "  # COMPLETE HERE\n",
        "  pass\n",
        "\n",
        "\n",
        "# DON'T MODIFY BELOW\n",
        "def load_pdb(pdb_id, chain_id):\n",
        "  pdbl = PDBList()\n",
        "  pdbp = PDBParser()\n",
        "  pdbl.retrieve_pdb_file(pdb_id.upper(), file_format=\"pdb\", pdir=\"./\")\n",
        "  struct = pdbp.get_structure(\"struct\", f\"pdb{pdb_id.lower()}.ent\")\n",
        "  model = struct[0]\n",
        "\n",
        "  sequence = []\n",
        "  coords = []\n",
        "  for chain in model:\n",
        "    if chain.id != chain_id:\n",
        "      continue\n",
        "    for residue in chain:\n",
        "      if residue.resname == \"HOH\":\n",
        "        continue\n",
        "      try:\n",
        "        coords.append(residue['CA'].get_vector().get_array())\n",
        "      except:\n",
        "        raise ValueError(\"There are missing atoms in this structure, try another!\")\n",
        "      resname = AA_NAME_MAP[residue.resname]\n",
        "      sequence.append(resname)\n",
        "\n",
        "  return \"\".join(sequence), np.array(coords)\n",
        "\n",
        "\n",
        "pdb_seq, coords = load_pdb(PDB_ID, PDB_CHAIN)\n",
        "contacts = compute_contacts(coords)\n",
        "plt.imshow(contacts)\n"
      ],
      "metadata": {
        "id": "-GjpMpxEvirR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.A.3 Question\n",
        "\n",
        "Now we will compute the predicted contacts using our PLM. Compare the predicted contacts and the ground truth contacts. How well do they match up? Inspect visually by plotting them using plt.imshow, and then compare using the mean average precision metric from sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html."
      ],
      "metadata": {
        "id": "CrMKV18vwT1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "def predict_contacts(model, alphabet, sequence):\n",
        "  \"\"\"Predict contacts with ESM.\"\"\"\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  data = [(\"prot\", sequence)]\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      num_layers = model.num_layers\n",
        "      results = model(batch_tokens, repr_layers=[num_layers], return_contacts=True)\n",
        "  token_representations = results[\"representations\"][num_layers]\n",
        "\n",
        "  tokens_len = batch_lens[0]\n",
        "  attention_contacts = results[\"contacts\"][0]\n",
        "  return attention_contacts[: tokens_len, : tokens_len]\n",
        "\n",
        "\n",
        "def compare_contacts(pred_contacts, true_contacts):\n",
        "  \"\"\"Compares two contact maps.\n",
        "\n",
        "  Prints the average precision and plots both maps.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  pred_contacts:\n",
        "    array of shape (num_residues, num_residues)\n",
        "  true_contacts:\n",
        "    array of shape (num_residues, num_residues)\n",
        "\n",
        "  \"\"\"\n",
        "  # COMPLETE HERE\n",
        "  # Make sure to flatten before computing the average precision\n",
        "  pass\n",
        "\n",
        "# we use the pdb_seq and contacts variables from the previous question\n",
        "pred_contacts = predict_contacts(esm6_model, esm6_alphabet, pdb_seq)\n",
        "compare_contacts(pred_contacts, contacts)\n",
        "\n"
      ],
      "metadata": {
        "id": "CaWfbsW20BdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.A.4 Question\n",
        "\n",
        "Try the same experiment with the esm150_model. Which performs best?"
      ],
      "metadata": {
        "id": "UpBlXsDpZ9s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE HERE\n",
        "# Try the esm150_model and the esm150_alphabet"
      ],
      "metadata": {
        "id": "T_P2-aAwZ9c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**:"
      ],
      "metadata": {
        "id": "jdT1bzdaaMW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3.B Structure Prediction\n",
        "\n",
        "In this problem, you will pick a protein sequence of interest and attempt to fold it using both AlphaFold2 and ESMFold. Pick from the PDB as before. You may want to filter to recently deposited structures since older ones will be in the training sets of AF2 and ESMFold. Make sure it's under 400 amino acids and doesn't contain missing residues.\n",
        "\n",
        "For instance you may use this one:\n",
        "PDB_ID = 8CH7, CHAIN_ID = \"A\" (https://www.rcsb.org/3d-view/8BY4)\n",
        "\n",
        "\n",
        "#### 3.B.1 Question\n",
        "\n",
        "First let's load the ground truth structure similarly to before. Print the sequence, you will need it for the next questions."
      ],
      "metadata": {
        "id": "q89OCFE4aUx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE HERE\n",
        "# Feel free to use a different PDB!\n",
        "PDB_ID = \"8CH7\"\n",
        "PDB_CHAIN = \"A\"\n",
        "pdb_seq, true_coords = load_pdb(PDB_ID, PDB_CHAIN)\n",
        "print(pdb_seq)"
      ],
      "metadata": {
        "id": "kSj-2qk6rrMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 3.B.2 Question\n",
        "\n",
        "Run your protein through AlphaFold2 using this notebook:\n",
        "https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb\n",
        "\n",
        "All you need to do is paste in your sequence from above and run all the cells. No need to modify any of the parameters. See the part that says:  \n",
        "`Input protein sequence(s), then hit Runtime -> Run all`\n",
        "\n",
        "This may take several minutes to complete. Once done, take a screenshot of the predicted structure and download results. The external notebook downloads zip file `jobname.result.zip` to your system. On extracting, among many other files, there are a sequence of PDB files out of which the one that is first generated can be uploaded. It will look something like this:  \n",
        "`<job_name>_unrelaxed_rank_005_alphafold2_ptm_model_1_seed_000.pdb`\n",
        "\n",
        "Upload any of the pdb files and the screenshot into this notebook using the files tab to the left. There's a button to upload files. Once uploaded you should press `copy file path` to get the correct paths for your uploads (they usually live under the `/content/` directory).\n",
        "\n",
        "Display you screenshot and load the pdb using the code provided."
      ],
      "metadata": {
        "id": "OgVLhi3JrqeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "def load_pdb_file(file_name):\n",
        "  pdbp = PDBParser()\n",
        "  struct = pdbp.get_structure(\"struct\", file_name)\n",
        "  model = struct[0]\n",
        "\n",
        "  sequence = []\n",
        "  coords = []\n",
        "  for chain in model:\n",
        "    if chain.id != \"A\":\n",
        "      continue\n",
        "    for residue in chain:\n",
        "      coords.append(residue['CA'].get_vector().get_array())\n",
        "      resname = AA_NAME_MAP[residue.resname]\n",
        "      sequence.append(residue.resname)\n",
        "\n",
        "  return \"\".join(sequence), np.array(coords)\n",
        "\n",
        "def display_image(file_name):\n",
        "  Image(filename=file_name)\n",
        "\n",
        "# COMPLETE HERE\n",
        "# load your structure & display the plot you downloaded\n",
        "# to get the correct path for your file, select it and press \"copy path\"\n",
        "af2_coords = ..."
      ],
      "metadata": {
        "id": "H28OKCpFcCL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.B.3 Question\n",
        "\n",
        "Now fold the same sequence using ESMFold.\n",
        "\n",
        "You can use this link. Just paste in your sequence and press \"fold\":  \n",
        "https://esmatlas.com/resources?action=fold\n",
        "\n",
        "Once you're done, take a screenshot of the predicted structure and download the PDB file. Upload both files again as you did in the previous problem, display the image here and load the pdb coordinates using the `load_pdb_file` above."
      ],
      "metadata": {
        "id": "hYWQn4Dycug6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE HERE\n",
        "esm2_coords = ..."
      ],
      "metadata": {
        "id": "U-WDjrOEd_ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.B.4 Question\n",
        "\n",
        "Now we will compare the two predictions. For this, you will compute the RMSD. Recall the RMSD:\n",
        "\n",
        "$$ f(x, y) = \\frac{1}{N} \\sum_{i=1}^N ||x_i - y_i||^2  \\\\\n",
        "RMSD(x, y) = \\sqrt{f(x, y)} $$\n",
        "\n",
        "\n",
        "First we will align the two structures and then we will compute the deviation. What is the RMSD between your two predicted structures? Do the models seem to agree? Compare to the ground truth PDB, which model performed best?"
      ],
      "metadata": {
        "id": "eJ6dOiq7eCPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.SVDSuperimposer import SVDSuperimposer\n",
        "\n",
        "def compute_rmsd(coords1, coords2):\n",
        "    \"\"\"This will align coords2 onto coords1.\"\"\"\n",
        "    sup = SVDSuperimposer()\n",
        "    sup.set(coords1, coords2)\n",
        "    sup.run()\n",
        "    rms = sup.get_rms()\n",
        "    return rms\n",
        "\n",
        "print(compute_rmsd(af2_coords, esm2_coords))\n",
        "print(compute_rmsd(af2_coords, true_coords))\n",
        "print(compute_rmsd(esm2_coords, true_coords))"
      ],
      "metadata": {
        "id": "KHwq_ridfS1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**:"
      ],
      "metadata": {
        "id": "KP18ciI5fTSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.C Structure-based sequence sesign (Optional for undegraduates, required for graduate students)\n",
        "\n",
        "In this problem, we will explore protein sequence design. Here we assume that we have a 3D structure and want to \"fit\" a sequence of amino acids to it. In practice there are tools you can use to generate protein backbones (ex: RFDiffusion). Here for simplicity, we assume that we have a 3D structure already.\n",
        "\n",
        "Use ProteinMPNN to redesign the sequence for the PDB file you used in the previous section (ex: 8CH7). All you need to do is run the first few setup cells and in the `Input Options` section, paste in the PDB ID (ex: `pdb: 8CH7`) and the chain to design (ex: `designed_chains: A`). Note that if your PDB has multiple chains (not the case for 8CH7), you may want to use the `fixed chains` options to fix the other chains.\n",
        "\n",
        "https://colab.research.google.com/github/dauparas/ProteinMPNN/blob/main/colab_notebooks/quickdemo.ipynb\n",
        "\n",
        "When you are done, you will obtain a new sequence (the one under the text `>T=0.1`).\n",
        "\n",
        "Past it below and try to fold it using either AF2 or ESMFold.\n",
        "\n",
        "Compute the RMSD between the new predicted fold and the original ground truth PDB.\n",
        "\n",
        "#### 3.C.1 Question\n",
        "\n",
        "How does the newly designed sequence compare to the original one. How does the predicted structures compare to original?\n",
        "\n"
      ],
      "metadata": {
        "id": "OPfoUZ8chdKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE HERE\n",
        "new_sequence = \"\"\n",
        "sequence_similarity = ...\n",
        "rmsd = ..."
      ],
      "metadata": {
        "id": "2qa_bov_iFrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**:"
      ],
      "metadata": {
        "id": "sg0mt5UQiGHW"
      }
    }
  ]
}