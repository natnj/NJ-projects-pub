{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natnj/NJ-projects-pub/blob/main/MLCB_Homework_NJ_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLCB Homework 4\n",
        "\n",
        "**Due: Monday Nov 13th at 11:59 PM EDT**\n",
        "\n",
        "If you have any questions, please ask on piazza or at office hours!\n",
        "\n",
        "Copy this notebook, and answer all questions directly in this notebook and complete the missing code where marked with **COMPLETE HERE**.\n",
        "\n",
        "When you are done, submit the .ipynb file as well as PDF to Canvas."
      ],
      "metadata": {
        "id": "L1qRVVbAk8_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Setup (run this)"
      ],
      "metadata": {
        "id": "fiaT0KjHlfgV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDQgDia7rwUQ"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install scanpy\n",
        "!pip install anndata\n",
        "!pip install leidenalg\n",
        "!pip install rdkit\n",
        "\n",
        "import scanpy as sc\n",
        "import anndata\n",
        "import os\n",
        "import pandas as pd\n",
        "import scipy.io as io\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from scipy.spatial.transform import Rotation\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "## Download the data\n",
        "!wget -c -O data.zip https://www.dropbox.com/sh/4f9fmenyvmrffj2/AAAmNwJtO8ZKTaRkZoltTCHsa?dl=0\n",
        "!unzip -o data.zip -d data\n",
        "\n",
        "!wget -c -O diffdock.zip https://www.dropbox.com/scl/fi/e23wyl4bfolckjaaablhc/diffdock.zip?rlkey=80p9a46yivyc3jdi7jnq7bnx9&dl=0\n",
        "!unzip -o diffdock.zip -d diffdock\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Single-cell RNA-seq Data Analysis\n",
        "\n",
        "In this problem, we will analyse single cell RNA-seq data, including clustering, identifying marker genes per cell type and look at differential expression under varied conditions.\n",
        "\n",
        "First run the extra setup below:"
      ],
      "metadata": {
        "id": "ftY20-dXuOZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Read data and create anndata object\n",
        "# load sparse matrix :\n",
        "X = io.mmread(\"data/counts.mtx\")\n",
        "# create anndata object\n",
        "adata = anndata.AnnData(X=X.transpose().tocsr() )\n",
        "# load cell metadata:\n",
        "cell_meta = pd.read_csv(\"data/meta.csv\")\n",
        "# load gene names:\n",
        "with open(\"data/gene_names.csv\", 'r') as f:\n",
        "    gene_names = f.read().splitlines()\n",
        "# set anndata observations and index obs by barcodes, var by gene names\n",
        "adata.obs = cell_meta\n",
        "adata.obs.index = adata.obs['barcode']\n",
        "adata.var.index = gene_names\n",
        "print(adata)"
      ],
      "metadata": {
        "id": "9EADs2piGdZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Since the provided data was pre-processed, we will skip the data fitering steps.\n",
        "## Perform log-transformation, scale data, and identify highly variable genes\n",
        "sc.pp.log1p(adata)\n",
        "sc.pp.scale(adata, max_value=10)\n",
        "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)"
      ],
      "metadata": {
        "id": "_roifKTUKsAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.A Visualization and Clustering"
      ],
      "metadata": {
        "id": "pY_G9xGt-nn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, you will perform dimensionality reduction (PCA) technique to emphasize the main axes of variation in the data, compuate neighborhood graph to identify clusters of cells that have similar expression patterns, run tSNE and UMAP for further dimensionality reduction to visualize clusters in 2D, and find clusters using Leiden graph-clustering method based on the neighborhood graph of cells, which you already computed in the previous section. Please use the scanpy build-in functions for this question."
      ],
      "metadata": {
        "id": "O6juUEFTdtss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Run PCA and plot\n"
      ],
      "metadata": {
        "id": "y1Wb3HfdM_fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Number of PCs selection\n"
      ],
      "metadata": {
        "id": "DyA_qtFHNDsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute neighborhood graph\n"
      ],
      "metadata": {
        "id": "-FW761l_mKD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Run clustering and plot\n"
      ],
      "metadata": {
        "id": "DR9VrbvVOEgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Run tSNE and plot, colored by cluster id which you get in the clustering step, colored by \"major.celltype\" in the metadata\n"
      ],
      "metadata": {
        "id": "pAok_KDvNeX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Run UMAP and plot, colored by cluster id which you get in the clustering step, colored by \"major.celltype\" in the metadata\n"
      ],
      "metadata": {
        "id": "gZR_LNSTNYSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the plots of tSNE and UMAP. Please also discuss the differences between these two methods in general."
      ],
      "metadata": {
        "id": "PnmSnqLvmWAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "8194v4guPoXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.B Find marker genes per cluster and annotate cell type"
      ],
      "metadata": {
        "id": "S7mIbkbhUuMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, you will identify marker genes for each cluster and use the reference marker panel to annotate the cell type for each cluster.\n",
        "Reference marker genes for the brain cell types:\n",
        "\n",
        "Markers | Cell Type\n",
        "---|---\n",
        "SYT1,SNAP25,GRIN1 | Neurons\n",
        "NRGN, SLC17A7,CAMK2A | Excitatory neurons\n",
        "GAD1,GAD2 |\tInhibitory neurons\n",
        "AQP4,GFAP |\tAstrocytes\n",
        "MBP, MOBP,PLP1 | \tOligodendrocytes\n",
        "CSF1R, CD74,C3 |\tMicroglia\n",
        "VCAN, PDGFRA,CSPG4 |\tOligodendrocyte progenitor cells (Opc)\n",
        "FLT1,CLDN5,AMBP |\tVascular cells"
      ],
      "metadata": {
        "id": "PAkyCWonSjrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find marker genes\n"
      ],
      "metadata": {
        "id": "POl2UCGkQSVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot UMAP colored with your cell type annotation and compare it with the \"major.celltype\" in the metadata\n"
      ],
      "metadata": {
        "id": "sZ4Vp0UmQjql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please describe your observation of the comparison between your annotation and \"major.celltype\"."
      ],
      "metadata": {
        "id": "wyiqRa7UUoir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "dcglnqO8u1__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.C Differential Gene Expression Analysis between Conditions"
      ],
      "metadata": {
        "id": "Zd59Kgiju1__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we will identify differentially expressed genes (DEGs) between conditions (AD vs. nonAD) per cell type. You may find the \"condition\" in the metadata. Please call DEGs using two methods: wilcoxon and t-test, visulize the top 10 DEGs per group, and compare your results between two methods and visulize the comparison using venn diagram. For each cell type, you will generate two comparions (up-regulated in AD; up-regulated in nonAD)."
      ],
      "metadata": {
        "id": "DfdHclINu1__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code and plot"
      ],
      "metadata": {
        "id": "n6YEIIAwz7jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:** explain your findings here"
      ],
      "metadata": {
        "id": "y3YSFeTuVCjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Molecular Docking\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vxRuKSYor1uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In lecture we studied the task of molecular docking: given a protein target's structure in 3D, we wish to find the 3D coordinates of a known ligand binder. In particular we showed some deep learning approaches to the problem.\n",
        "\n",
        "In this problem, we first review the question of symmetry preserving models, which is particuarly important to 3D tasks such as molecular docking. Then, we will run a few docking predictions using DiffDock (https://arxiv.org/abs/2210.01776) and analyze them."
      ],
      "metadata": {
        "id": "-xZ7yx6U-Vaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.A Invariance & Equivariance\n",
        "\n",
        "Because the docking task is inherently a 3D task (i.e we are predicting coordinates), it's important to think about the geometrical symmetries that we wish our model to handle gracefully. We call this family of models \"invariant\" or \"equivariant\" to a group transformation. This is particularly neat property that significantly reduces the space of functions that the model considers, helping optimization and generalization.\n",
        "\n",
        "#### 2.A.1 Question\n",
        "\n",
        "What does it mean for a model to be invariant to translations and rotations of the input? How about equivariant? Give a simple mathematical definition using `f` as the model function, `x` as the input, `R` as a rotation matrix, and `t` as a translation vector."
      ],
      "metadata": {
        "id": "nqh21cvZFQDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**:"
      ],
      "metadata": {
        "id": "Cryz5DDHFSzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.A.2 Question\n",
        "\n",
        "There are many ways to achieve invariance / equivariance, and it is currently a very active area of research. Here, we will study the the Equivariant Graph Neural Network (EGNN)  model by Satoras et. al: (https://arxiv.org/pdf/2102.09844.pdf).\n",
        "\n",
        "Recall the GNN layer we implemented in Homework 2, with node features `h` and edge features `e`. We compute messages for each edge, aggregate the messages and used the result to update the features:\n",
        "\n",
        "$$ \\begin{align} m_{ij} &= MLP(h_i, h_j, e_{ij}) \\\\\n",
        " m_i &= \\frac{1}{N} \\sum_j m_{ij} \\\\\n",
        " \\tilde{h_i} &= MLP(h_i, m_i) \\end{align}$$\n",
        "\n",
        "\n",
        "An EGNN layer is very similar, defined by the following set of equations, given a set of input features `h` and coordinates `x`:\n",
        "\n",
        "$$ \\begin{align} m_{ij} &= MLP(h_i, h_j, e_{ij}, ||x_i - x_j||^2) \\\\\n",
        " m_i &= \\frac{1}{N} \\sum_j m_{ij} \\\\\n",
        "h_{new} &= MLP(h_i, m_i) \\\\\n",
        "x_{new} &= x_i + \\frac{1}{N} \\sum_j MLP(m_{ij}) \\cdot (\\vec{x_i}- \\vec{x_j}) \\end{align}$$\n",
        "\n",
        "\n",
        "The only changes are the use of pairwise distances in the first equation and the coordinate update in the last equation.\n",
        "\n",
        "Prove that EGNN is indeed equivariant to translation and rotation by showing that applying a rotation `R` and translation `t` to the input `x_i` and `x_j` is equivalent to applying it to the output `x_new`.\n"
      ],
      "metadata": {
        "id": "NKakSWGPImjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**:"
      ],
      "metadata": {
        "id": "pxO0xb3g8O82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.A.3 Question\n",
        "\n",
        "We will now implement the EGNN and verify its equivariance. Fill out the code below.\n",
        "\n"
      ],
      "metadata": {
        "id": "n_rbWEKB8QyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HELPERS\n",
        "class MLP(object):\n",
        "  \"\"\"A random two layer neural network.\"\"\"\n",
        "\n",
        "  def __init__(self, in_dim, out_dim):\n",
        "    self.w1 = np.random.randn(in_dim, out_dim)\n",
        "    self.b1 = np.random.randn(out_dim)\n",
        "    self.w2 = np.random.randn(out_dim, out_dim)\n",
        "    self.b2 = np.random.randn(out_dim)\n",
        "\n",
        "  def forward(self, h):\n",
        "    h_new = np.dot(h, self.w1) + self.b1\n",
        "    h_new = h_new * (h_new > 0)\n",
        "    h_new = np.dot(h_new, self.w2) + self.b2\n",
        "    return h_new\n",
        "\n",
        "  def __call__(self, h):\n",
        "    return self.forward(h)\n",
        "\n",
        "\n",
        "def apply_transform(R, t, x):\n",
        "  \"\"\"Apply a rotation and translation to a set of points.\"\"\"\n",
        "  return np.dot(x, R.T) + t\n",
        "\n",
        "\n",
        "# COMPLETE BELOW\n",
        "class EGNN(object):\n",
        "\n",
        "  def __init__(self, dim):\n",
        "    \"\"\"Random weight initialization.\"\"\"\n",
        "    self.message_mlp = MLP(dim * 3 + 1, dim)\n",
        "    self.feature_mlp = MLP(dim * 2, dim)\n",
        "    self.coords_mlp = MLP(dim, 1)\n",
        "\n",
        "  def forward(self, h, e, x):\n",
        "    \"\"\"Apply an EGNN layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    h:\n",
        "      node features as a numpy array of shape (N, D)\n",
        "    e:\n",
        "      edge features as a numpy array of shape (N, N, D)\n",
        "    x:\n",
        "      set of points in 3D as a numpy array of shape (N, 3)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    h_new:\n",
        "      new node features as a numpy array of shape (N, D)\n",
        "    x_new:\n",
        "      new set of points in 3D as a numpy array of shape (N, 3)\n",
        "\n",
        "    \"\"\"\n",
        "    # COMPLETE HERE\n",
        "\n",
        "    # Expand h to get all pairs of h's, your final dimension should be (N, N, 2 * D)\n",
        "    # You can expand with dummy dimensions and then use np.repeat\n",
        "\n",
        "    # Get all x_i - x_j vectors (you can just broadcast, without repeat)\n",
        "\n",
        "    # Compute the squared norm of the x_ij vectors\n",
        "\n",
        "    # Concatenate h pairs, distances, and edge features\n",
        "\n",
        "    # Compute messages for all i, j pairs\n",
        "\n",
        "    # Aggregate messages per node (sum across j)\n",
        "\n",
        "    # Update features\n",
        "\n",
        "    # Update coordinates\n",
        "    pass\n",
        "\n",
        "\n",
        "# DO NOT MODIFY BELOW\n",
        "def test_equivariance():\n",
        "  # Set parameters\n",
        "  N = 64\n",
        "  D = 32\n",
        "  h = np.random.randn(N, D)\n",
        "  e = np.random.randn(N, N, D)\n",
        "  x = np.random.randn(N, 3)\n",
        "  egnn = EGNN(D)\n",
        "\n",
        "  # Sample a random roto-translation\n",
        "  R = Rotation.random().as_matrix()\n",
        "  t = np.random.randn(3)\n",
        "  x_rot = apply_transform(R, t, x)\n",
        "\n",
        "  # Run model on x\n",
        "  _, x_new = egnn.forward(h, e, x)\n",
        "  x_new_rot = apply_transform(R, t, x_new)\n",
        "\n",
        "  # Run the model on x_rot\n",
        "  _, x_rot_new = egnn.forward(h, e, x_rot)\n",
        "\n",
        "  # Compare the outputs\n",
        "  if np.linalg.norm(x_new_rot - x_rot_new, axis=-1).max() < 1e-4:\n",
        "    print(\"Equivariance test passed!\")\n",
        "  else:\n",
        "    print(\"Equivariance test failed!\")\n",
        "\n",
        "\n",
        "test_equivariance()"
      ],
      "metadata": {
        "id": "mX-TqIwPO3tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.B DiffDock\n",
        "\n",
        "In this second part, we will use a state of the art deep learning tool, DiffDock, to produce candidate docking structures. We will analyze the results to get some insight into the inner workings of the model.\n",
        "\n",
        "DiffDock also uses a 3D equivariant model, though it is not the EGNN introduced above but a tensor field network. These are more complex, and we will not study them in this course. If you are interested, you may read more about them here:\n",
        "https://arxiv.org/abs/1802.08219. For this problem, we will instead focus on a different charachteristic of DiffDock: the \"diffusion\" process."
      ],
      "metadata": {
        "id": "WFmy-RedNp7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.B.1 Question\n",
        "\n",
        "DiffDock is a generative model. Explain the difference between a generative and a discriminative model."
      ],
      "metadata": {
        "id": "4hbDoGywly8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**:"
      ],
      "metadata": {
        "id": "zDtJsNW9DXLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.B.2 Question\n",
        "\n",
        "DiffDock is a specific type of generative model, namely a diffusion-based model. These models are trained to iteratively reverse a noise distribution (ex: gaussian) to the data distribution. Due to their generative nature, they can be sampled from, and every sample requires a certain number of denoising steps. For more info, see this very good blog post:\n",
        "\n",
        "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\n",
        "\n",
        "You are provided with pre-computed structures from DiffDock for this problem. If you are interested in making your own predictions you may use this colab notebook:\n",
        "\n",
        "https://colab.research.google.com/github/hgbrian/biocolabs/blob/master/DiffDock.ipynb\n",
        "\n",
        "We pre-computed docking results using the notebook above with different number of denoising steps (i.e inference steps): 5, 10, 20. For each setting we sampled 5 possible poses. First let's print the data we have."
      ],
      "metadata": {
        "id": "jnDFdB3BDbUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS\n",
        "DIFFDOCK_DATA = \"/content/diffdock/diffdock/\"\n",
        "GT_PATH = \"6o5g_B_LMJ.sdf\"\n",
        "\n",
        "ground_truth = os.path.join(DIFFDOCK_DATA, GT_PATH)\n",
        "predictions = []\n",
        "for file_name in os.listdir(DIFFDOCK_DATA):\n",
        "  if \"rank\" not in file_name:\n",
        "    continue\n",
        "  else:\n",
        "    meta = file_name.split(\"_\")\n",
        "    group = meta[0]\n",
        "    rank = int(meta[2][-1])\n",
        "    confidence = float(meta[3].split(\"confidence\")[1][:-4])\n",
        "    predictions.append({\n",
        "        \"path\": os.path.join(DIFFDOCK_DATA, file_name),\n",
        "        \"group\": group,\n",
        "        \"rank\": rank,\n",
        "        \"confidence\": confidence\n",
        "    })\n",
        "\n",
        "print(\"Ground truth path:\\n\")\n",
        "print(ground_truth)\n",
        "\n",
        "print(\"\\nPredictions:\")\n",
        "print(pd.DataFrame(predictions))"
      ],
      "metadata": {
        "id": "tTHGm5ZnFBJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each of the 3 groups (i.e 5, 10 and 20), report the best RMSD across the 5 samples. How did performance change as a function of the number of denoising steps?"
      ],
      "metadata": {
        "id": "MHApjI8AE5sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HELPERS\n",
        "def load_coordinates_sdf(path):\n",
        "    \"\"\"Load molecule from sdf.\"\"\"\n",
        "    suppl = Chem.SDMolSupplier(path)\n",
        "    mol = next(suppl)\n",
        "    return mol\n",
        "\n",
        "def compute_rmsd(mol1, mol2):\n",
        "    \"\"\"Compute the RMSD between mol1 and mol2.\"\"\"\n",
        "    return Chem.rdMolAlign.CalcRMS(mol1, mol2)\n",
        "\n",
        "# COMPLETE HERE"
      ],
      "metadata": {
        "id": "u9mpi0qE6T8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "SrZIQTWt6Upl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.B.3 Question\n",
        "\n",
        "Perform the same analysis, this time comparing strategies for measuring performance across the 5 samples:\n",
        "\n",
        "- The mean RMSD (same as before)\n",
        "- The best RMSD of the 5 samples\n",
        "- The highest confidence ranked of the 5 samples\n",
        "\n",
        "Comment on your observations."
      ],
      "metadata": {
        "id": "lZloh_bL6aBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE HERE"
      ],
      "metadata": {
        "id": "RcoVSr0l6VpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "8sRrr6Rs7lja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.B.4 Question\n",
        "\n",
        "Visualize the worst and the best prediction (according to the RMSD) using the Molstar visualizer (https://molstar.org/viewer/).\n",
        "\n",
        "You can just drag and drop the files directly on your browser, super easy. Make sure to visualize both the sdf file (molecule prediction) and the ground truth PDB (target protein + correct molecule pose). Take screenshots for tbe best and worst predictions and display them here."
      ],
      "metadata": {
        "id": "jD-T1HLsA_pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the best file and download it by running this cell\n",
        "# Do not include the /content/diffdock/diffdock prefix\n",
        "best_prediction = \"\"\n",
        "worst_prediction = \"\"\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "\n",
        "DIFFDOCK_DATA = \"/content/diffdock/diffdock/\"\n",
        "files.download(os.path.join(DIFFDOCK_DATA, best_prediction))\n",
        "files.download(os.path.join(DIFFDOCK_DATA, worst_prediction))\n",
        "files.download(os.path.join(DIFFDOCK_DATA, \"6O5G.pdb\"))"
      ],
      "metadata": {
        "id": "lLV5PpiIBQsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you notice anything interesting about the \"bad\" prediction?"
      ],
      "metadata": {
        "id": "XNzy0bbGjvFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**"
      ],
      "metadata": {
        "id": "KNQPyy_wjwI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.B.5 Question (Optional for all students)\n",
        "\n",
        "Try your own! Find a known protein-drug interaction and attempt to dock the molecule. Here are the steps you can follow:\n",
        "\n",
        "1. Find a known protein-drug interaction in the Drugbank: https://go.drugbank.com/\n",
        "2. Get the PDB ID for the target protein (if there isn't one, look for a uniprot ID and find the predicted structure in the AlphaFold2 database: https://alphafold.ebi.ac.uk/)\n",
        "3. Get the smiles string for the ligand\n",
        "4. Dock using this notebook: https://colab.research.google.com/github/hgbrian/biocolabs/blob/master/DiffDock.ipynb\n",
        "5. Display your prediction here, you can use https://molstar.org/viewer/"
      ],
      "metadata": {
        "id": "rDUr6mzT-twJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVcaDqko__fJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}